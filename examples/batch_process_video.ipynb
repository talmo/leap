{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Predict body part positions from an MP4 file\n",
    "This notebook presents an example pipeline for applying a trained LEAP network to ~360k frames read from an MP4 video.\n",
    "\n",
    "You can download the data to reproduce the benchmarking results below.\n",
    "\n",
    "**Input data:** [072212_163153.mp4](https://1drv.ms/v/s!AnmpIqqfwz3zgcgekCxNp-MN76p1UQ) (254 MiB)\n",
    "\n",
    "**Output data:** [072212_163153.preds.h5](https://1drv.ms/u/s!AnmpIqqfwz3zgcgdDhQrKRsBaxvCXQ) (46.9 MiB)\n",
    "\n",
    "The trained network can be found in the repository [models folder](https://github.com/talmo/leap/tree/master/models/BermanFlies/FlyAging-DiegoCNN_v1.0_filters%3D64_rot%3D15_lrfactor%3D0.1_lrmindelta%3D1e-05_01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive\\code\\leap\\examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Windows-10-10.0.16299-SP0\n",
      "h5py:\n",
      "Summary of the h5py configuration\n",
      "---------------------------------\n",
      "\n",
      "h5py    2.7.1\n",
      "HDF5    1.10.1\n",
      "Python  3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n",
      "sys.platform    win32\n",
      "sys.maxsize     9223372036854775807\n",
      "numpy   1.14.1\n",
      "\n",
      "Keras: 2.1.4\n",
      "Tensorflow: 1.5.0\n",
      "Devices:\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8438345468058077117\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9143884186\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 3667598826921976706\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9143884186\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 1568816340487803239\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Yuck -- hackish relative importing:\n",
    "import os, sys\n",
    "print(os.getcwd())\n",
    "if os.path.exists(os.path.join(os.getcwd(), \"leap\", \"predict_box.py\")):\n",
    "    leap_dir = os.path.join(os.getcwd())\n",
    "elif os.path.exists(os.path.join(os.path.dirname(os.getcwd()), \"leap\", \"predict_box.py\")):\n",
    "    leap_dir = os.path.join(os.path.dirname(os.getcwd()))\n",
    "# leap_dir = \"..\" # replace this with the absolute path if imports are not working\n",
    "sys.path.append(leap_dir) # add path to repository root\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "from time import time\n",
    "\n",
    "import keras\n",
    "import keras.models\n",
    "from leap.predict_box import convert_to_peak_outputs\n",
    "from leap.utils import versions\n",
    "\n",
    "versions(list_devices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media file path\n",
    "video_path = \"D:/tmp/072212_163153.mp4\"\n",
    "\n",
    "# Trained network path\n",
    "model_path = \"D:/OneDrive/code/leap/models/BermanFlies/FlyAging-DiegoCNN_v1.0_filters=64_rot=15_lrfactor=0.1_lrmindelta=1e-05_01/final_model.h5\"\n",
    "\n",
    "# Predictions output path\n",
    "save_path = \"D:/tmp/072212_163153.preds.h5\"\n",
    "\n",
    "# Number of frames to read before predicting (higher = faster, but limited by RAM)\n",
    "chunk_size = 10000\n",
    "\n",
    "# Number of frames to evaluate at once on the GPU (higher = faster, but limited by GPU memory)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: D:/OneDrive/code/leap/models/BermanFlies/FlyAging-DiegoCNN_v1.0_filters=64_rot=15_lrfactor=0.1_lrmindelta=1e-05_01/final_model.h5\n",
      "    Input: (None, 192, 192, 1)\n",
      "    Output: (None, 3, 32)\n",
      "Predicted: 10000/361000 frames | Elapsed: 0.7 min / 231.6 FPS / ETA: 25.3 min\n",
      "Predicted: 20000/361000 frames | Elapsed: 1.4 min / 245.6 FPS / ETA: 23.1 min\n",
      "Predicted: 30000/361000 frames | Elapsed: 2.0 min / 250.4 FPS / ETA: 22.0 min\n",
      "Predicted: 40000/361000 frames | Elapsed: 2.6 min / 253.0 FPS / ETA: 21.1 min\n",
      "Predicted: 50000/361000 frames | Elapsed: 3.3 min / 254.4 FPS / ETA: 20.4 min\n",
      "Predicted: 60000/361000 frames | Elapsed: 3.9 min / 255.5 FPS / ETA: 19.6 min\n",
      "Predicted: 70000/361000 frames | Elapsed: 4.6 min / 256.2 FPS / ETA: 18.9 min\n",
      "Predicted: 80000/361000 frames | Elapsed: 5.2 min / 257.3 FPS / ETA: 18.2 min\n",
      "Predicted: 90000/361000 frames | Elapsed: 5.8 min / 258.3 FPS / ETA: 17.5 min\n",
      "Predicted: 100000/361000 frames | Elapsed: 6.4 min / 259.2 FPS / ETA: 16.8 min\n",
      "Predicted: 110000/361000 frames | Elapsed: 7.1 min / 259.9 FPS / ETA: 16.1 min\n",
      "Predicted: 120000/361000 frames | Elapsed: 7.7 min / 260.4 FPS / ETA: 15.4 min\n",
      "Predicted: 130000/361000 frames | Elapsed: 8.3 min / 260.5 FPS / ETA: 14.8 min\n",
      "Predicted: 140000/361000 frames | Elapsed: 9.0 min / 260.5 FPS / ETA: 14.1 min\n",
      "Predicted: 150000/361000 frames | Elapsed: 9.6 min / 260.5 FPS / ETA: 13.5 min\n",
      "Predicted: 160000/361000 frames | Elapsed: 10.2 min / 260.4 FPS / ETA: 12.9 min\n",
      "Predicted: 170000/361000 frames | Elapsed: 10.9 min / 260.4 FPS / ETA: 12.2 min\n",
      "Predicted: 180000/361000 frames | Elapsed: 11.5 min / 260.5 FPS / ETA: 11.6 min\n",
      "Predicted: 190000/361000 frames | Elapsed: 12.1 min / 260.8 FPS / ETA: 10.9 min\n",
      "Predicted: 200000/361000 frames | Elapsed: 12.8 min / 261.1 FPS / ETA: 10.3 min\n",
      "Predicted: 210000/361000 frames | Elapsed: 13.4 min / 261.4 FPS / ETA: 9.6 min\n",
      "Predicted: 220000/361000 frames | Elapsed: 14.0 min / 261.7 FPS / ETA: 9.0 min\n",
      "Predicted: 230000/361000 frames | Elapsed: 14.6 min / 261.9 FPS / ETA: 8.3 min\n",
      "Predicted: 240000/361000 frames | Elapsed: 15.3 min / 262.1 FPS / ETA: 7.7 min\n",
      "Predicted: 250000/361000 frames | Elapsed: 15.9 min / 262.4 FPS / ETA: 7.1 min\n",
      "Predicted: 260000/361000 frames | Elapsed: 16.5 min / 262.5 FPS / ETA: 6.4 min\n",
      "Predicted: 270000/361000 frames | Elapsed: 17.1 min / 262.7 FPS / ETA: 5.8 min\n",
      "Predicted: 280000/361000 frames | Elapsed: 17.8 min / 262.9 FPS / ETA: 5.1 min\n",
      "Predicted: 290000/361000 frames | Elapsed: 18.4 min / 263.0 FPS / ETA: 4.5 min\n",
      "Predicted: 300000/361000 frames | Elapsed: 19.0 min / 263.2 FPS / ETA: 3.9 min\n",
      "Predicted: 310000/361000 frames | Elapsed: 19.6 min / 263.3 FPS / ETA: 3.2 min\n",
      "Predicted: 320000/361000 frames | Elapsed: 20.2 min / 263.4 FPS / ETA: 2.6 min\n",
      "Predicted: 330000/361000 frames | Elapsed: 20.9 min / 263.5 FPS / ETA: 2.0 min\n",
      "Predicted: 340000/361000 frames | Elapsed: 21.5 min / 263.6 FPS / ETA: 1.3 min\n",
      "Predicted: 350000/361000 frames | Elapsed: 22.1 min / 263.5 FPS / ETA: 0.7 min\n",
      "Predicted: 360000/361000 frames | Elapsed: 22.8 min / 263.5 FPS / ETA: 0.1 min\n",
      "Predicted: 361000/361000 frames | Elapsed: 22.8 min / 263.4 FPS / ETA: 0.0 min\n",
      "Finished predicting 361000 frames.\n",
      "    Prediction | Runtime: 22.04 min / 272.953 FPS\n",
      "    Reading    | Runtime: 0.74 min / 8133.876 FPS\n",
      "Saved: D:/tmp/072212_163153.preds.h5\n",
      "Total runtime: 22.9 mins\n",
      "Total performance: 262.900 FPS\n"
     ]
    }
   ],
   "source": [
    "t0_all = time()\n",
    "\n",
    "# Load model and convert to peak-coordinate output\n",
    "model = convert_to_peak_outputs(keras.models.load_model(model_path))\n",
    "print(\"Model:\", model_path)\n",
    "print(\"    Input:\", str(model.input_shape))\n",
    "print(\"    Output:\", str(model.output_shape))\n",
    "\n",
    "# model = keras.utils.multi_gpu_model(model, gpus=2)\n",
    "\n",
    "# Open video for reading\n",
    "reader = cv2.VideoCapture(video_path)\n",
    "num_samples = int(reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialize\n",
    "positions_pred = []\n",
    "conf_pred = []\n",
    "buffer = []\n",
    "samples_predicted = 0\n",
    "reading_runtime = 0\n",
    "prediction_runtime = 0\n",
    "done = False\n",
    "\n",
    "# Process video chunk-by-chunk\n",
    "while not done:\n",
    "    t0_reading = time()\n",
    "    # Read and finish if no frame was retrieved\n",
    "    returned_frame, I = reader.read()\n",
    "    done = not returned_frame\n",
    "    reading_runtime += time() - t0_reading\n",
    "    \n",
    "    # Add current frame to buffer\n",
    "    if not done:\n",
    "        buffer.append(I[...,0])\n",
    "    \n",
    "    # Do we have anything to predict?\n",
    "    if len(buffer) >= chunk_size or (done and len(buffer) > 0):\n",
    "        t0_prediction = time()\n",
    "        \n",
    "        # Predict on buffer\n",
    "        Y = model.predict(np.stack(buffer, axis=0)[...,None], batch_size=batch_size)\n",
    "        \n",
    "        # Save\n",
    "        positions_pred.append(Y[:,:2,:].astype(\"int32\"))\n",
    "        conf_pred.append(Y[:,2,:].squeeze())\n",
    "        \n",
    "        # Empty out buffer container\n",
    "        buffer = []\n",
    "        \n",
    "        # Performance stats\n",
    "        samples_predicted += len(Y)\n",
    "        prediction_runtime += time() - t0_prediction\n",
    "        elapsed = time() - t0_all\n",
    "        fps = samples_predicted / elapsed\n",
    "        print(\"Predicted: %d/%d frames | Elapsed: %.1f min / %.1f FPS / ETA: %.1f min\" %\n",
    "              (samples_predicted, num_samples, elapsed / 60, fps, (num_samples - samples_predicted) / fps / 60))\n",
    "        \n",
    "# Close video reader\n",
    "reader.release()\n",
    "\n",
    "# Merge arrays\n",
    "positions_pred = np.concatenate(positions_pred, axis=0)\n",
    "conf_pred = np.concatenate(conf_pred, axis=0)\n",
    "\n",
    "# Report performance stats\n",
    "print(\"Finished predicting %d frames.\" % samples_predicted)\n",
    "print(\"    Prediction | Runtime: %.2f min / %.3f FPS\" % (prediction_runtime / 60, samples_predicted / prediction_runtime))\n",
    "print(\"    Reading    | Runtime: %.2f min / %.3f FPS\" % (reading_runtime / 60, samples_predicted / reading_runtime))\n",
    "\n",
    "# Save\n",
    "if os.path.exists(save_path):\n",
    "    os.remove(save_path)\n",
    "with h5py.File(save_path, \"w\") as f:\n",
    "        f.attrs[\"num_samples\"] = num_samples\n",
    "        f.attrs[\"video_path\"] = video_path\n",
    "        f.attrs[\"model_path\"] = model_path\n",
    "\n",
    "        ds_pos = f.create_dataset(\"positions_pred\", data=positions_pred, compression=\"gzip\", compression_opts=1)\n",
    "        ds_pos.attrs[\"description\"] = \"coordinate of peak at each sample\"\n",
    "        ds_pos.attrs[\"dims\"] = \"(sample, [x, y], joint) === (sample, [column, row], joint)\"\n",
    "\n",
    "        ds_conf = f.create_dataset(\"conf_pred\", data=conf_pred, compression=\"gzip\", compression_opts=1)\n",
    "        ds_conf.attrs[\"description\"] = \"confidence map value in [0, 1.0] at peak\"\n",
    "        ds_conf.attrs[\"dims\"] = \"(sample, joint)\"\n",
    "\n",
    "        total_runtime = time() - t0_all\n",
    "        f.attrs[\"reading_runtime_secs\"] = reading_runtime\n",
    "        f.attrs[\"prediction_runtime_secs\"] = prediction_runtime\n",
    "        f.attrs[\"total_runtime_secs\"] = total_runtime\n",
    "        \n",
    "    \n",
    "print(\"Saved:\", save_path)\n",
    "\n",
    "print(\"Total runtime: %.1f mins\" % (total_runtime / 60))\n",
    "print(\"Total performance: %.3f FPS\" % (samples_predicted / total_runtime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
